#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ JSON —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–æ–≤
–¥–ª—è —Ä–∞–±–æ—Ç—ã –Ω–∞ GitHub Pages –±–µ–∑ —Å–µ—Ä–≤–µ—Ä–∞
"""

import json
import os
from api_server import scrape_all_pages

def create_static_products_file():
    """–°–æ–∑–¥–∞–µ—Ç —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π JSON —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–æ–≤"""
    
    print("–ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤...")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–æ–≤
        products = scrape_all_pages()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        products_data = []
        for product in products:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ BeautifulSoup –æ–±—ä–µ–∫—Ç–∞
            product_data = {
                "name": product.get_text().strip() if hasattr(product, 'get_text') else str(product),
                "image": "./images/Discontinued.jpg",  # –ó–∞–≥–ª—É—à–∫–∞
                "price": 0,
                "newPrice": 0,
                "oldPrice": 0,
                "availability": "–í –Ω–∞–ª–∏—á–∏–∏",
                "rating": "5.0"
            }
            products_data.append(product_data)
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
        data = {
            "products": products_data,
            "total": len(products_data),
            "hasMore": False
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON —Ñ–∞–π–ª
        with open('static_products.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìä –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products_data)}")
        print(f"üíæ –§–∞–π–ª: static_products.json")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")

if __name__ == "__main__":
    create_static_products_file()
